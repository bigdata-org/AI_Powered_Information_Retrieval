name : ETL using Docling

on:
  workflow_dispatch:
  
jobs:
  etl:
    runs-on: ubuntu-latest
    env:
      BUCKET_NAME: ${{ secrets.AWS_BUCKET_NAME}}
      REGION: ${{ secrets.AWS_REGION }}

    steps:
      - name: Debug GitHub Event
        run : echo "${{ github.event_name}}"

      - name: Checkout repository
        uses : actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Cache docling models
        uses: actions/cache@v3
        with:
          path: ~/.cache/docling
          key: ${{ runner.os }}-docling-models


      - name: Install dependencies
        run: pip install docling boto3 python-dotenv requests

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Debug environment variables
        run: |
          echo "Checking environment variables (values hidden):"
          echo "BUCKET_NAME is set: ${{ env.BUCKET_NAME != '' }}"
          echo "REGION is set: ${{ env.REGION != '' }}"
          echo "AWS credentials configured: ${{ env.AWS_ACCESS_KEY_ID != '' }}"

      - name: Run Python script for ETL using Docling
        env: 
          BUCKET_NAME: ${{ secrets.AWS_BUCKET_NAME}}
          REGION: ${{ secrets.AWS_REGION }}

        run: python backend/etl_docling.py

  load-s3-metadata:
    needs: etl
    runs-on : ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name:  Install dependencies
      run: pip install boto3 python-dotenv requests

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Load s3 url to metadata
      env: 
          BUCKET_NAME: ${{ secrets.AWS_BUCKET_NAME}}
          REGION: ${{ secrets.AWS_REGION }}
      run : python backend/load_s3_metadata.py

  trigger-databricks:
      # needs: load-s3-metadata
      runs-on: ubuntu-latest
      steps:
        - name: Checkout repository
          uses: actions/checkout@v4

        - name: Trigger Databricks jobs
          env:
            DATABRICKS_HOST: ${{ vars.DATABRICKS_HOST }}
            DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }} 
          run: |
             curl -X POST \
             -H "Authorization: Bearer $DATABRICKS_TOKEN" \
             -H "Content-Type: application/json" \
             "https://$DATABRICKS_HOST/api/2.0/jobs/run-now" \
             -d '{ 
              "job_id": "619557985935110", 
              "job_parameters": {
              "tool": "docling"
              }
             }'